# -*- coding: utf-8 -*-
"""
Created on Fri Nov 25 15:01:08 2022

@author: md arman hossain

link: https://nvd.nist.gov/vuln/data-feeds
"""
import hashlib
import requests
import os
import zipfile
import git
def localMetadata(year):
    filename = './downloaded/nvdcve-1.1-'+str(year)+'.json'
    isExist = os.path.exists(filename)
    if not isExist: return ""
    sha256_hash = hashlib.sha256()
    with open(filename,"rb") as f:
        # Read and update hash string value in blocks of 4K
        for byte_block in iter(lambda: f.read(4096),b""):
            sha256_hash.update(byte_block)
        sha256 = sha256_hash.hexdigest().lower()
        # print(sha256)
        return sha256
    
# metadata
def remoteMetadata(year):
    URL = "https://nvd.nist.gov/feeds/json/cve/1.1/" + 'nvdcve-1.1-'+str(year)+".meta"
    response = requests.get(URL)
    rstring = response.content.decode("utf-8").lower()
    pos  = rstring.find('sha256:')
    sha256 = rstring[pos+7:-2]
    # print(sha256)
    return sha256

def checkMetadata(year):
    localMeta = localMetadata(year)
    remoteMeta = remoteMetadata(year)
    if remoteMeta!="": shouldProceed = True
    else: shouldProceed = False
    # print(localMeta,remoteMeta)
    return localMeta == remoteMeta, shouldProceed

import json 

def downloadAndExtractZip(year):
    
    URL = "https://nvd.nist.gov/feeds/json/cve/1.1/" + 'nvdcve-1.1-'+str(year)+".json.zip"
    response = requests.get(URL,stream=True)
    chunk_size = 128
    with open('./downloaded/zip.zip', 'wb') as fd:
        for chunk in response.iter_content(chunk_size=chunk_size):
            fd.write(chunk)
            
    # response.content

    with zipfile.ZipFile('./downloaded/zip.zip', 'r') as zip_ref:
        zip_ref.extractall('./downloaded')
        
def download_exploit_db():
    URL = 'https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_exploits.csv?inline=false'
    response = requests.get(URL,stream=True)
    chunk_size = 128
    with open('./downloaded/files_exploits.csv', 'wb') as fd:
        for chunk in response.iter_content(chunk_size=chunk_size):
            fd.write(chunk)
            
def download_epss_scores():
    URL = 'https://epss.cyentia.com/epss_scores-current.csv.gz'
    response = requests.get(URL,stream=True)
    chunk_size = 128
    with open('./downloaded/epss_scores-current.csv.gz', 'wb') as fd:
        for chunk in response.iter_content(chunk_size=chunk_size):
            fd.write(chunk)
            
def updatedata():
    isExist = os.path.exists('./downloaded')
    if not isExist: os.mkdir('./downloaded')
    
    isExist = os.path.exists('./data')
    if not isExist: os.mkdir('./data')
    
    startyear = 2002
    modified = []
    while(True):
        match,proceed = checkMetadata(startyear)
        if not match:
            print('updating year : '+ str(startyear))
            downloadAndExtractZip(startyear)
            modified.append(startyear)
        if not proceed:
            break
        
        startyear+=1
        # print(startyear)
    lst2 = ['recent','modified']
    for i in range(len(lst2)):
        match,proceed = checkMetadata(lst2[i])
        if not match:
            print('updating year : '+ lst2[i])
            downloadAndExtractZip(lst2[i])
            modified.append(startyear)
            
    download_epss_scores()
    download_exploit_db()
    
    return modified

if __name__ == "__main__":
    updatedata()
